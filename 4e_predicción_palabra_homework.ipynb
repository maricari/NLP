{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maricari/NLP/blob/main/4e_predicci%C3%B3n_palabra_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto utilizando la layer Embedding de Keras. Se utilizará esos embeddings junto con layers LSTM para predeccir la próxima posible palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "# largo de la secuencia, incluye seq input + word output\n",
        "train_len = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para plotear\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "HthK840egnPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset el libro *I. Origen de los indios de América.* disponible en www.gutemberg.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IkdPfrQJZdB5"
      },
      "outputs": [],
      "source": [
        "# Para leer y parsear el texto en HTML\n",
        "import urllib.request\n",
        "import bs4 as bs\n",
        "\n",
        "# Para limpiar el texto\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j-3nQ4lZjfb"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.gutenberg.org/cache/epub/56219/pg56219-images.html')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsea el artículo\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = list()\n",
        "flag = 0 # para quedarse únicamente la parte I del libro\n",
        "for para in article_paragraphs:\n",
        "  text = (re.sub(r'\\s+', ' ', para.text)).replace('\\'','')\n",
        "  text = re.sub(r'\\[[0-9]+\\]', '', text)\n",
        "  if text == '':\n",
        "    continue\n",
        "  if flag:\n",
        "    article_text.append(text)\n",
        "  else:\n",
        "    if 'grandes y heróicas civilizaciones indianas de esas mismas épocas' in text:\n",
        "      flag = 1\n",
        "  if 'FIN DE LA PRIMERA PARTE' in text:\n",
        "    break\n",
        "article_text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(article_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDocF9z3JcQW",
        "outputId": "60453f18-81cc-4367-a4e0-f61d8dd9aff7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1213"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# muestra del texto\n",
        "article_text[1080:1090]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDPJVU0JLu0J",
        "outputId": "2be75c19-d5ce-4514-bd09-fc7cfad01903"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rabihorcado, ave grande de rapiña cuyas alas desplegadas ocupan el espacio de catorce pies, y es de mucho vuelo, pues apesar de ser terrestre, extiende su vuelo hasta treinta leguas y más, dentro del mar.',\n",
              " 'Rabo de junco, ave terrestre muy grande, que tiene la cola larga y muy delgada, que también vuela en el mar á grandes distancias.',\n",
              " 'Sinsonte, ave de canto tan armonioso que se le considera como el rey de las aves, por su canto y trinos que embelezan.',\n",
              " 'Tángara, especie de gorrión, propio de los países equinocciales de América.',\n",
              " 'Tucán, especie de picazo; es ave propia del Brasil.',\n",
              " 'Tinamón, gallinacea, exclusivamente propia de la América Meridional.',\n",
              " 'Turpian, cuyo canto es muy agradable y entretenido.',\n",
              " 'Toro-Pisco, de lindo color, con un moño en forma de plumero.',\n",
              " 'Trompetero, que tiene la particularidad de cantar por el ano.',\n",
              " 'Tijeras-Chupa, cuya cola está en forma de tijeras.']"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDoouHp7Zp6D"
      },
      "source": [
        "### 1 - Ejemplo de Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Zf3O7eK6ZpP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "141d2ee0-d2e0-4311-e585-4a5c31feeaf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tucán, especie de picazo; es ave propia del Brasil.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# texto de muestra\n",
        "text = article_text[1084]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "AOv67Sj7aeFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b9bbde-34de-4c91-c117-9b723813d617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tucán', 'especie', 'de', 'picazo', 'es', 'ave', 'propia', 'del', 'brasil']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Transformar las oraciones en tokens\n",
        "tokens = text_to_word_sequence(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "A659lswTbIIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50238714-22a7-4779-8009-26b9d8f3608b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['tucán', 'especie', 'de', 'picazo'],\n",
              " ['especie', 'de', 'picazo', 'es'],\n",
              " ['de', 'picazo', 'es', 'ave'],\n",
              " ['picazo', 'es', 'ave', 'propia'],\n",
              " ['es', 'ave', 'propia', 'del']]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Desfazaje de las palabras según el train_len\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)\n",
        "text_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fkPNvXeQcS0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717b8e5f-0424-4263-927f-f91b21c46b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 5, 3, 1], [5, 3, 1, 2], [3, 1, 2, 4], [1, 2, 4, 6], [2, 4, 6, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "tok = Tokenizer() \n",
        "\n",
        "# Creates the vocabulary index based on word frequency.\n",
        "tok.fit_on_texts(text_sequences)\n",
        "\n",
        "# Transforms each text to a sequence of integers\n",
        "sequences = tok.texts_to_sequences(text_sequences)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "3ro81yCQc1oX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8e84b0-a575-46b1-afec-ea5d37bfb9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "print(tok.document_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "nzAWNfroc4u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c409a80-2c80-4600-9320-c5f7a7f4aa37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('tucán', 1),\n",
              "             ('especie', 2),\n",
              "             ('de', 3),\n",
              "             ('picazo', 4),\n",
              "             ('es', 4),\n",
              "             ('ave', 3),\n",
              "             ('propia', 2),\n",
              "             ('del', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "tok.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "spTBxmFQc6h8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5a5c47-181d-45e0-9ab2-b9bc9f31d18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'picazo': 1, 'es': 2, 'de': 3, 'ave': 4, 'especie': 5, 'propia': 6, 'tucán': 7, 'del': 8}\n"
          ]
        }
      ],
      "source": [
        "# El índice para cada palabra\n",
        "# El sistema las ordena de las más populares a las menos populares\n",
        "print(tok.word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohS5Tao1d2KB"
      },
      "source": [
        "### 2 - Preprocesamiento completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "XH_L14Wjaowe"
      },
      "outputs": [],
      "source": [
        "# Recorre todas las filas y transforma las oraciones\n",
        "# en secuencias de palabras\n",
        "sentence_tokens = []\n",
        "for i in range(len(article_text)):\n",
        "    sentence_tokens.append(text_to_word_sequence(article_text[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[1084]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeS5AO9RNjA2",
        "outputId": "c43ebf2d-dcbc-41bf-98e6-c1c4ab526306"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tucán', 'especie', 'de', 'picazo', 'es', 'ave', 'propia', 'del', 'brasil']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kILsSoxTuHEr"
      },
      "outputs": [],
      "source": [
        "# Concatena todos los rows en un corpus\n",
        "df = pd.DataFrame(article_text)\n",
        "corpus = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=0)[0]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "_KlsYd7_uOez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed347ed-1513-4b25-ca9b-1bc4a9682e02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['antes',\n",
              " 'de',\n",
              " 'abordar',\n",
              " 'el',\n",
              " 'asunto',\n",
              " 'del',\n",
              " 'presente',\n",
              " 'trabajo',\n",
              " 'debemos',\n",
              " 'indicar',\n",
              " 'de',\n",
              " 'preferencia',\n",
              " 'cuáles',\n",
              " 'fueron',\n",
              " 'los',\n",
              " 'habitantes',\n",
              " 'del',\n",
              " 'continente',\n",
              " 'de',\n",
              " 'américa']"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "# Transformar el corpus a tokens\n",
        "tokens=text_to_word_sequence(corpus)\n",
        "tokens[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GlqpZSJOJ1xQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139cdfaf-b4a6-4f1b-ae29-2ab6c6a3efb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de tokens en el corpus: 51728\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de tokens en el corpus:\", len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RhQevOynuYk2"
      },
      "outputs": [],
      "source": [
        "# Desfazaje de las palabras según el train_len\n",
        "text_sequences = []\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "FU3FuqHSuhzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1bafde-45c2-4503-81eb-50df8470c41a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['antes', 'de', 'abordar', 'el'],\n",
              " ['de', 'abordar', 'el', 'asunto'],\n",
              " ['abordar', 'el', 'asunto', 'del'],\n",
              " ['el', 'asunto', 'del', 'presente'],\n",
              " ['asunto', 'del', 'presente', 'trabajo'],\n",
              " ['del', 'presente', 'trabajo', 'debemos'],\n",
              " ['presente', 'trabajo', 'debemos', 'indicar'],\n",
              " ['trabajo', 'debemos', 'indicar', 'de'],\n",
              " ['debemos', 'indicar', 'de', 'preferencia'],\n",
              " ['indicar', 'de', 'preferencia', 'cuáles']]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "text_sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "064N2jtLvHRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e82e01d-ef33-4e90-f273-b05876394f67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[69, 1, 9374, 7],\n",
              " [1, 9374, 7, 1012],\n",
              " [9374, 7, 1012, 8],\n",
              " [7, 1012, 8, 1595],\n",
              " [1012, 8, 1595, 2231],\n",
              " [8, 1595, 2231, 1013],\n",
              " [1595, 2231, 1013, 1232],\n",
              " [2231, 1013, 1232, 1],\n",
              " [1013, 1232, 1, 3602],\n",
              " [1232, 1, 3602, 2232]]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Proceso de tokenizacion\n",
        "tok = Tokenizer() \n",
        "tok.fit_on_texts(text_sequences) \n",
        "sequences = tok.texts_to_sequences(text_sequences)\n",
        "sequences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMVP4bj0vL2e"
      },
      "source": [
        "### 3 - Input y target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "e1vJTG65v4Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e67358-6f32-4dd8-9f8f-c88ade83e4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51724, 3)\n",
            "(51724,)\n"
          ]
        }
      ],
      "source": [
        "# Separar las palabras objetivos (target) que el modelo debe predecir.\n",
        "arr_sequences = np.array(sequences)\n",
        "x_data = arr_sequences[:,:-1]\n",
        "y_data_int = arr_sequences[:,-1]\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data_int.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras del vocabulario\n",
        "tok.index_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPCWlhMasVz",
        "outputId": "b5c3a1e1-1e18-4d69-eaa7-261245c67433"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'de',\n",
              " 2: 'la',\n",
              " 3: 'y',\n",
              " 4: 'que',\n",
              " 5: 'en',\n",
              " 6: 'los',\n",
              " 7: 'el',\n",
              " 8: 'del',\n",
              " 9: 'las',\n",
              " 10: 'á',\n",
              " 11: 'se',\n",
              " 12: 'por',\n",
              " 13: 'es',\n",
              " 14: 'su',\n",
              " 15: 'ó',\n",
              " 16: 'con',\n",
              " 17: 'américa',\n",
              " 18: 'una',\n",
              " 19: 'para',\n",
              " 20: 'un',\n",
              " 21: 'al',\n",
              " 22: 'más',\n",
              " 23: 'como',\n",
              " 24: 'sus',\n",
              " 25: 'no',\n",
              " 26: 'muy',\n",
              " 27: 'también',\n",
              " 28: 'lo',\n",
              " 29: 'otros',\n",
              " 30: 'entre',\n",
              " 31: 'este',\n",
              " 32: 'color',\n",
              " 33: 'continente',\n",
              " 34: 'perú',\n",
              " 35: 'pues',\n",
              " 36: 'son',\n",
              " 37: 'hasta',\n",
              " 38: 'especie',\n",
              " 39: 'cuya',\n",
              " 40: 'planta',\n",
              " 41: 'algunos',\n",
              " 42: 'méxico',\n",
              " 43: 'río',\n",
              " 44: 'indios',\n",
              " 45: 'tan',\n",
              " 46: 'han',\n",
              " 47: 'isla',\n",
              " 48: 'años',\n",
              " 49: 'desde',\n",
              " 50: 'mundo',\n",
              " 51: 'sobre',\n",
              " 52: 'ha',\n",
              " 53: 'árbol',\n",
              " 54: 'fueron',\n",
              " 55: 'fué',\n",
              " 56: 'hay',\n",
              " 57: 'parte',\n",
              " 58: 'otras',\n",
              " 59: 'tierra',\n",
              " 60: 'autores',\n",
              " 61: 'después',\n",
              " 62: 'gran',\n",
              " 63: 'donde',\n",
              " 64: 'contra',\n",
              " 65: 'cuyas',\n",
              " 66: 'nuevo',\n",
              " 67: 'esta',\n",
              " 68: 'americano',\n",
              " 69: 'antes',\n",
              " 70: 'dos',\n",
              " 71: 'raza',\n",
              " 72: 'islas',\n",
              " 73: 'época',\n",
              " 74: 'mismo',\n",
              " 75: 'piedra',\n",
              " 76: 'tiene',\n",
              " 77: 'cuyo',\n",
              " 78: 'sido',\n",
              " 79: 'dice',\n",
              " 80: 'ríos',\n",
              " 81: 'algunas',\n",
              " 82: 'antiguos',\n",
              " 83: 'era',\n",
              " 84: 'ser',\n",
              " 85: 'madera',\n",
              " 86: 'aún',\n",
              " 87: 'sin',\n",
              " 88: 'asia',\n",
              " 89: 'según',\n",
              " 90: 'mar',\n",
              " 91: 'opinión',\n",
              " 92: 'oro',\n",
              " 93: 'pero',\n",
              " 94: 'estos',\n",
              " 95: 'propio',\n",
              " 96: 'tiempo',\n",
              " 97: 'ellos',\n",
              " 98: 'esa',\n",
              " 99: 'hojas',\n",
              " 100: 'nombre',\n",
              " 101: 'allí',\n",
              " 102: 'é',\n",
              " 103: 'norte',\n",
              " 104: 'ecuador',\n",
              " 105: 'hombres',\n",
              " 106: 'tribus',\n",
              " 107: 'cap',\n",
              " 108: 'territorio',\n",
              " 109: 'obra',\n",
              " 110: 'brasil',\n",
              " 111: 'tiempos',\n",
              " 112: 'muchos',\n",
              " 113: 'siglos',\n",
              " 114: 'plata',\n",
              " 115: 'habitantes',\n",
              " 116: 'fin',\n",
              " 117: 'razas',\n",
              " 118: 'unos',\n",
              " 119: 'ese',\n",
              " 120: 'si',\n",
              " 121: 'atlántida',\n",
              " 122: 'produce',\n",
              " 123: 'así',\n",
              " 124: 'pueblos',\n",
              " 125: 'cual',\n",
              " 126: 'bosques',\n",
              " 127: 'porque',\n",
              " 128: 'primeros',\n",
              " 129: 'origen',\n",
              " 130: 'todos',\n",
              " 131: 'estas',\n",
              " 132: 'africa',\n",
              " 133: 'tres',\n",
              " 134: 'durante',\n",
              " 135: 'blanco',\n",
              " 136: 'todo',\n",
              " 137: 'siendo',\n",
              " 138: 'fenicios',\n",
              " 139: 'sólo',\n",
              " 140: 'costa',\n",
              " 141: 'año',\n",
              " 142: 'costas',\n",
              " 143: 'chile',\n",
              " 144: 'hecho',\n",
              " 145: 'europa',\n",
              " 146: 'le',\n",
              " 147: 'tanto',\n",
              " 148: 'grandes',\n",
              " 149: 'rojo',\n",
              " 150: 'propia',\n",
              " 151: 'lib',\n",
              " 152: 'sirve',\n",
              " 153: 'civilización',\n",
              " 154: '000',\n",
              " 155: 'demás',\n",
              " 156: 'hoy',\n",
              " 157: 'colombia',\n",
              " 158: 'animales',\n",
              " 159: 'ophir',\n",
              " 160: 'siglo',\n",
              " 161: 'diversas',\n",
              " 162: 'lugar',\n",
              " 163: 'costumbres',\n",
              " 164: 'hace',\n",
              " 165: 'estado',\n",
              " 166: 'otra',\n",
              " 167: 'toda',\n",
              " 168: 'esas',\n",
              " 169: 'esos',\n",
              " 170: 'rey',\n",
              " 171: 'indias',\n",
              " 172: 'él',\n",
              " 173: 'habían',\n",
              " 174: 'todas',\n",
              " 175: 'muchas',\n",
              " 176: 'suelo',\n",
              " 177: 'ya',\n",
              " 178: 'además',\n",
              " 179: 'varios',\n",
              " 180: 'sea',\n",
              " 181: 'aquellos',\n",
              " 182: 'guerra',\n",
              " 183: 'blanca',\n",
              " 184: 'arbusto',\n",
              " 185: 'originario',\n",
              " 186: 'comarcas',\n",
              " 187: 'algo',\n",
              " 188: 'guerras',\n",
              " 189: 'negro',\n",
              " 190: 'mayor',\n",
              " 191: 'haber',\n",
              " 192: 'diluvio',\n",
              " 193: 'antiguo',\n",
              " 194: 'historia',\n",
              " 195: 'romanos',\n",
              " 196: 'ave',\n",
              " 197: 'cuando',\n",
              " 198: 'sino',\n",
              " 199: 'respecto',\n",
              " 200: 'misma',\n",
              " 201: 'continentes',\n",
              " 202: 'chinos',\n",
              " 203: 'batalla',\n",
              " 204: 'originaria',\n",
              " 205: 'cerca',\n",
              " 206: 'varias',\n",
              " 207: 'grande',\n",
              " 208: 'región',\n",
              " 209: 'playas',\n",
              " 210: 'océano',\n",
              " 211: 'otro',\n",
              " 212: 'puede',\n",
              " 213: 'nueva',\n",
              " 214: 'indígenas',\n",
              " 215: 'dicho',\n",
              " 216: 'está',\n",
              " 217: 'cartagineses',\n",
              " 218: 'hombre',\n",
              " 219: 'salomón',\n",
              " 220: 'casi',\n",
              " 221: 'seguida',\n",
              " 222: 'familia',\n",
              " 223: 'tienen',\n",
              " 224: 'san',\n",
              " 225: 'bolivia',\n",
              " 226: 'sud',\n",
              " 227: 'parece',\n",
              " 228: 'cuanto',\n",
              " 229: 'p',\n",
              " 230: 'viaje',\n",
              " 231: 'descubrimiento',\n",
              " 232: 'comarca',\n",
              " 233: 'cuyos',\n",
              " 234: 'argentina',\n",
              " 235: 'amarillo',\n",
              " 236: 'especies',\n",
              " 237: 'americanos',\n",
              " 238: 'ii',\n",
              " 239: 'navegación',\n",
              " 240: 'éstos',\n",
              " 241: 'uno',\n",
              " 242: 'semejante',\n",
              " 243: 'forma',\n",
              " 244: 'dura',\n",
              " 245: 'cura',\n",
              " 246: 'meridional',\n",
              " 247: 'conquista',\n",
              " 248: 'juan',\n",
              " 249: 'país',\n",
              " 250: 'cada',\n",
              " 251: 'pág',\n",
              " 252: 'ellas',\n",
              " 253: 'china',\n",
              " 254: 'reino',\n",
              " 255: 'cuatro',\n",
              " 256: 'tamaño',\n",
              " 257: 'existencia',\n",
              " 258: 'menos',\n",
              " 259: 'sustancia',\n",
              " 260: 'colón',\n",
              " 261: 'número',\n",
              " 262: 'pacífico',\n",
              " 263: 'nos',\n",
              " 264: 'plantas',\n",
              " 265: 'estrecho',\n",
              " 266: 'i',\n",
              " 267: 'metal',\n",
              " 268: 'llamada',\n",
              " 269: 'halla',\n",
              " 270: 'naciones',\n",
              " 271: 'hacia',\n",
              " 272: 'eran',\n",
              " 273: 'imperio',\n",
              " 274: 'atlántico',\n",
              " 275: 'ni',\n",
              " 276: 'paraguay',\n",
              " 277: 'minas',\n",
              " 278: 'dicen',\n",
              " 279: 'opiniones',\n",
              " 280: 'usos',\n",
              " 281: 'platón',\n",
              " 282: 'teñir',\n",
              " 283: 'flor',\n",
              " 284: 'panamá',\n",
              " 285: 'andes',\n",
              " 286: 'países',\n",
              " 287: 'escritores',\n",
              " 288: 'aquella',\n",
              " 289: 'historiadores',\n",
              " 290: 'largo',\n",
              " 291: 'cuerpo',\n",
              " 292: 'ella',\n",
              " 293: 'groenlandia',\n",
              " 294: 'negra',\n",
              " 295: 'azul',\n",
              " 296: 'septentrional',\n",
              " 297: 'lenguas',\n",
              " 298: 'bastante',\n",
              " 299: 'aquellas',\n",
              " 300: 'cristiana',\n",
              " 301: 'solamente',\n",
              " 302: 'libro',\n",
              " 303: 'egipcios',\n",
              " 304: 'hebreos',\n",
              " 305: 'poco',\n",
              " 306: 'autor',\n",
              " 307: 'mil',\n",
              " 308: 'regiones',\n",
              " 309: 'cabeza',\n",
              " 310: 'sirven',\n",
              " 311: 'canadá',\n",
              " 312: 'cuales',\n",
              " 313: 'mucho',\n",
              " 314: 'provincia',\n",
              " 315: 'cordillera',\n",
              " 316: 'diferentes',\n",
              " 317: 'tal',\n",
              " 318: 'unas',\n",
              " 319: 'creer',\n",
              " 320: 'pobladores',\n",
              " 321: 'universal',\n",
              " 322: 'americanas',\n",
              " 323: 'griegos',\n",
              " 324: 'medio',\n",
              " 325: 'tuvo',\n",
              " 326: 'descendientes',\n",
              " 327: 'encontró',\n",
              " 328: 'lugares',\n",
              " 329: 'larga',\n",
              " 330: 'tierras',\n",
              " 331: 'animal',\n",
              " 332: 'árboles',\n",
              " 333: 'encuentra',\n",
              " 334: 'sur',\n",
              " 335: 'humano',\n",
              " 336: 'ruinas',\n",
              " 337: 'primero',\n",
              " 338: 'existen',\n",
              " 339: 'principalmente',\n",
              " 340: 'siempre',\n",
              " 341: 'mismos',\n",
              " 342: 'épocas',\n",
              " 343: 'género',\n",
              " 344: 'noé',\n",
              " 345: 'a',\n",
              " 346: 'tradición',\n",
              " 347: 'sitio',\n",
              " 348: 'llamado',\n",
              " 349: 'verde',\n",
              " 350: 'extrae',\n",
              " 351: 'agradable',\n",
              " 352: 'plumaje',\n",
              " 353: 'bajo',\n",
              " 354: 'fuerte',\n",
              " 355: 'había',\n",
              " 356: 'guatemala',\n",
              " 357: 'monumentos',\n",
              " 358: 'yucatán',\n",
              " 359: 'colonias',\n",
              " 360: 'materia',\n",
              " 361: 'sol',\n",
              " 362: 'antigua',\n",
              " 363: 'inmigraciones',\n",
              " 364: 'creación',\n",
              " 365: 'partes',\n",
              " 366: 'hacer',\n",
              " 367: 'primitivos',\n",
              " 368: 'españa',\n",
              " 369: 'egipto',\n",
              " 370: 'diversos',\n",
              " 371: 'numerosas',\n",
              " 372: 'expedición',\n",
              " 373: 'pies',\n",
              " 374: 'alejandro',\n",
              " 375: 'hermoso',\n",
              " 376: 'india',\n",
              " 377: 'mineral',\n",
              " 378: 'sabor',\n",
              " 379: 'corteza',\n",
              " 380: 'dulce',\n",
              " 381: 'hizo',\n",
              " 382: 'estados',\n",
              " 383: 'ambas',\n",
              " 384: 'entonces',\n",
              " 385: 'decir',\n",
              " 386: 'tuvieron',\n",
              " 387: 'tenido',\n",
              " 388: 'hemos',\n",
              " 389: 'cabo',\n",
              " 390: 'efecto',\n",
              " 391: 'semejanza',\n",
              " 392: 'hechos',\n",
              " 393: 'modernos',\n",
              " 394: 'veces',\n",
              " 395: 'diez',\n",
              " 396: 'modo',\n",
              " 397: 'poblaron',\n",
              " 398: 'aunque',\n",
              " 399: 'suponer',\n",
              " 400: 'batallas',\n",
              " 401: 'ciudad',\n",
              " 402: '»',\n",
              " 403: 'hayan',\n",
              " 404: 'mr',\n",
              " 405: 'haya',\n",
              " 406: 'escandinavos',\n",
              " 407: 'naturaleza',\n",
              " 408: 'colores',\n",
              " 409: 'preciosa',\n",
              " 410: 'purgante',\n",
              " 411: 'raíz',\n",
              " 412: 'fruto',\n",
              " 413: 'caracteres',\n",
              " 414: 'principales',\n",
              " 415: 'orden',\n",
              " 416: 'alto',\n",
              " 417: 'montañas',\n",
              " 418: 'sangre',\n",
              " 419: 'extensión',\n",
              " 420: 'consiguiente',\n",
              " 421: 'venezuela',\n",
              " 422: 'españoles',\n",
              " 423: 'istmo',\n",
              " 424: 'americana',\n",
              " 425: 'dios',\n",
              " 426: 'expediciones',\n",
              " 427: 'remotos',\n",
              " 428: 'sabios',\n",
              " 429: 'conocida',\n",
              " 430: 'supone',\n",
              " 431: 'cinco',\n",
              " 432: 'firme',\n",
              " 433: 'siguientes',\n",
              " 434: 'tenía',\n",
              " 435: 'gusto',\n",
              " 436: 'hijo',\n",
              " 437: 'luego',\n",
              " 438: 'flota',\n",
              " 439: 'islandia',\n",
              " 440: 'trascurso',\n",
              " 441: 'toma',\n",
              " 442: 'común',\n",
              " 443: 'olor',\n",
              " 444: 'brillante',\n",
              " 445: 'oscuro',\n",
              " 446: 'agua',\n",
              " 447: 'fruta',\n",
              " 448: 'cola',\n",
              " 449: 'cristóbal',\n",
              " 450: 'antillas',\n",
              " 451: 'territorios',\n",
              " 452: 'poder',\n",
              " 453: 'general',\n",
              " 454: 'occidental',\n",
              " 455: 'oeste',\n",
              " 456: 'pueblo',\n",
              " 457: 'unidos',\n",
              " 458: 'hallan',\n",
              " 459: 'ningún',\n",
              " 460: 'podido',\n",
              " 461: 'últimos',\n",
              " 462: 'luchas',\n",
              " 463: 'manera',\n",
              " 464: 'vida',\n",
              " 465: 'pasaron',\n",
              " 466: 'primeras',\n",
              " 467: 'talvez',\n",
              " 468: 'proceden',\n",
              " 469: 'días',\n",
              " 470: 'debajo',\n",
              " 471: 'asevera',\n",
              " 472: 'nombres',\n",
              " 473: 'quizá',\n",
              " 474: 'j',\n",
              " 475: 'arte',\n",
              " 476: 'citados',\n",
              " 477: 'construcción',\n",
              " 478: 'notable',\n",
              " 479: 'fuera',\n",
              " 480: 'iii',\n",
              " 481: 'hacen',\n",
              " 482: 'duda',\n",
              " 483: 'navíos',\n",
              " 484: 'prueba',\n",
              " 485: 'vez',\n",
              " 486: 'piedras',\n",
              " 487: 'especialmente',\n",
              " 488: 'aquel',\n",
              " 489: 'invasión',\n",
              " 490: 'tantas',\n",
              " 491: 'período',\n",
              " 492: 'amarilla',\n",
              " 493: 'generalmente',\n",
              " 494: 'plomo',\n",
              " 495: 'duro',\n",
              " 496: 'eficaz',\n",
              " 497: 'jugo',\n",
              " 498: 'hemisferio',\n",
              " 499: 'indiana',\n",
              " 500: 'república',\n",
              " 501: 'superior',\n",
              " 502: 'llegó',\n",
              " 503: 'centro',\n",
              " 504: 'hicieron',\n",
              " 505: 'santa',\n",
              " 506: 'conocimiento',\n",
              " 507: 'archipiélago',\n",
              " 508: 'amazonas',\n",
              " 509: 'les',\n",
              " 510: 'fuerza',\n",
              " 511: 'armas',\n",
              " 512: 'originarios',\n",
              " 513: 'apesar',\n",
              " 514: 'opina',\n",
              " 515: 'judíos',\n",
              " 516: 'último',\n",
              " 517: 'iv',\n",
              " 518: 'mujeres',\n",
              " 519: 'oriental',\n",
              " 520: 'dr',\n",
              " 521: 'opinan',\n",
              " 522: 'atenienses',\n",
              " 523: 'igualmente',\n",
              " 524: 'dar',\n",
              " 525: 'fenicia',\n",
              " 526: 'pudo',\n",
              " 527: 'central',\n",
              " 528: 'x',\n",
              " 529: 'mongoles',\n",
              " 530: 'tocante',\n",
              " 531: 'jerusalem',\n",
              " 532: 'tarsdchisch',\n",
              " 533: 'mares',\n",
              " 534: 'etc',\n",
              " 535: 'combate',\n",
              " 536: 'solo',\n",
              " 537: 'vegetal',\n",
              " 538: 'gris',\n",
              " 539: 'compacta',\n",
              " 540: 'estaban',\n",
              " 541: 'distintas',\n",
              " 542: 'habría',\n",
              " 543: 'estaba',\n",
              " 544: 'mississipí',\n",
              " 545: 'tarde',\n",
              " 546: 'numerosos',\n",
              " 547: 'provincias',\n",
              " 548: 'ahora',\n",
              " 549: 'enfermedades',\n",
              " 550: 'propiedades',\n",
              " 551: 'fuego',\n",
              " 552: 'día',\n",
              " 553: 'tradiciones',\n",
              " 554: 'fundándose',\n",
              " 555: 'analogías',\n",
              " 556: 'probar',\n",
              " 557: 'agrega',\n",
              " 558: 'gomara',\n",
              " 559: 'probable',\n",
              " 560: 'fr',\n",
              " 561: 'garcía',\n",
              " 562: 'c',\n",
              " 563: 'apoyo',\n",
              " 564: 'ix',\n",
              " 565: 'posteriormente',\n",
              " 566: 'buques',\n",
              " 567: 'punto',\n",
              " 568: 'occidentales',\n",
              " 569: 'reinos',\n",
              " 570: 'canto',\n",
              " 571: 'suponen',\n",
              " 572: 'terminó',\n",
              " 573: 'comunicación',\n",
              " 574: 'objetos',\n",
              " 575: 'metales',\n",
              " 576: 'natural',\n",
              " 577: 'gente',\n",
              " 578: 'mapas',\n",
              " 579: 'francos',\n",
              " 580: 'siria',\n",
              " 581: 'grecia',\n",
              " 582: 'vencidos',\n",
              " 583: 'menor',\n",
              " 584: 'edad',\n",
              " 585: 'palma',\n",
              " 586: 'propiedad',\n",
              " 587: 'curar',\n",
              " 588: 'estimada',\n",
              " 589: 'instrumentos',\n",
              " 590: 'resina',\n",
              " 591: 'semillas',\n",
              " 592: 'lana',\n",
              " 593: 'alimento',\n",
              " 594: 'anfibio',\n",
              " 595: 'alas',\n",
              " 596: 'primera',\n",
              " 597: 'notables',\n",
              " 598: 'california',\n",
              " 599: 'missouri',\n",
              " 600: 'cuenta',\n",
              " 601: 'interior',\n",
              " 602: 'seis',\n",
              " 603: 'algún',\n",
              " 604: 'esto',\n",
              " 605: 'pueden',\n",
              " 606: 'familias',\n",
              " 607: 'tener',\n",
              " 608: 'bien',\n",
              " 609: 'ambos',\n",
              " 610: 'primitiva',\n",
              " 611: 'conservan',\n",
              " 612: 'invasiones',\n",
              " 613: 'tratado',\n",
              " 614: 'descienden',\n",
              " 615: 'cataclismo',\n",
              " 616: 'fundamento',\n",
              " 617: 'etnógrafos',\n",
              " 618: 'evidente',\n",
              " 619: 'aristóteles',\n",
              " 620: 'maderas',\n",
              " 621: 'poblar',\n",
              " 622: 'sucesivamente',\n",
              " 623: 'largas',\n",
              " 624: 'pasando',\n",
              " 625: 'antiguas',\n",
              " 626: 'reyes',\n",
              " 627: 'lengua',\n",
              " 628: 'sostener',\n",
              " 629: 'debe',\n",
              " 630: 'pasar',\n",
              " 631: 'sabio',\n",
              " 632: 'gregorio',\n",
              " 633: 'abundancia',\n",
              " 634: 'viajes',\n",
              " 635: 'persas',\n",
              " 636: 'relaciones',\n",
              " 637: 'pequeño',\n",
              " 638: 'humboldt',\n",
              " 639: 'pelo',\n",
              " 640: 'artes',\n",
              " 641: 'juicio',\n",
              " 642: 'llegaron',\n",
              " 643: 'nativo',\n",
              " 644: 'caso',\n",
              " 645: 'parecido',\n",
              " 646: 'llama',\n",
              " 647: 'blancos',\n",
              " 648: 'creemos',\n",
              " 649: 'tantos',\n",
              " 650: 'antediluviana',\n",
              " 651: 'duró',\n",
              " 652: 'resultado',\n",
              " 653: 'abundante',\n",
              " 654: 'posible',\n",
              " 655: 'erick',\n",
              " 656: 'piel',\n",
              " 657: 'trasparente',\n",
              " 658: 'leche',\n",
              " 659: 'estimulante',\n",
              " 660: 'vive',\n",
              " 661: 'pájaro',\n",
              " 662: 'grado',\n",
              " 663: 'nación',\n",
              " 664: 'luz',\n",
              " 665: 'lago',\n",
              " 666: 'situada',\n",
              " 667: 'escritura',\n",
              " 668: 'orillas',\n",
              " 669: 'pudieron',\n",
              " 670: 'segundo',\n",
              " 671: 'ingleses',\n",
              " 672: 'aborígenes',\n",
              " 673: 'todavía',\n",
              " 674: 'golfo',\n",
              " 675: 'australes',\n",
              " 676: 'oriente',\n",
              " 677: 'orientales',\n",
              " 678: 'están',\n",
              " 679: 'muerte',\n",
              " 680: 'ello',\n",
              " 681: 'carne',\n",
              " 682: 'sería',\n",
              " 683: 'estudio',\n",
              " 684: 'noticias',\n",
              " 685: 'venido',\n",
              " 686: 'alguna',\n",
              " 687: 'ciertas',\n",
              " 688: 'antigüedad',\n",
              " 689: 'remota',\n",
              " 690: 'catástrofe',\n",
              " 691: 'quien',\n",
              " 692: 'clase',\n",
              " 693: 'habiendo',\n",
              " 694: 'comercio',\n",
              " 695: 'santo',\n",
              " 696: 'domingo',\n",
              " 697: 'letras',\n",
              " 698: 'anteriores',\n",
              " 699: 'uso',\n",
              " 700: 'investigaciones',\n",
              " 701: 'azores',\n",
              " 702: 'sostienen',\n",
              " 703: 'leyes',\n",
              " 704: 'sicilia',\n",
              " 705: 'aportaron',\n",
              " 706: 'afirman',\n",
              " 707: 'encontrado',\n",
              " 708: 'cantidad',\n",
              " 709: 'hacía',\n",
              " 710: 'vinieron',\n",
              " 711: 'encontraron',\n",
              " 712: 'primer',\n",
              " 713: 'empero',\n",
              " 714: 'pasado',\n",
              " 715: 'roma',\n",
              " 716: 'marino',\n",
              " 717: 'innumerables',\n",
              " 718: 'obras',\n",
              " 719: 'seda',\n",
              " 720: '3',\n",
              " 721: 'parvaim',\n",
              " 722: 'naves',\n",
              " 723: 'preciosas',\n",
              " 724: 'dan',\n",
              " 725: 'allá',\n",
              " 726: 'ciencia',\n",
              " 727: 'canarias',\n",
              " 728: 'of',\n",
              " 729: 'palabra',\n",
              " 730: 'habrían',\n",
              " 731: 'ejército',\n",
              " 732: 'millones',\n",
              " 733: 'ruta',\n",
              " 734: 'hierro',\n",
              " 735: 'pesado',\n",
              " 736: 'dúctil',\n",
              " 737: 'pardo',\n",
              " 738: 'granos',\n",
              " 739: 'usa',\n",
              " 740: 'emplea',\n",
              " 741: 'goma',\n",
              " 742: 'ebanistería',\n",
              " 743: 'casas',\n",
              " 744: 'negras',\n",
              " 745: 'conejo',\n",
              " 746: 'aves',\n",
              " 747: 'pico',\n",
              " 748: 'carácter',\n",
              " 749: 'teniendo',\n",
              " 750: 'segunda',\n",
              " 751: 'citaremos',\n",
              " 752: 'tribu',\n",
              " 753: 'florida',\n",
              " 754: 'gobierno',\n",
              " 755: 'debido',\n",
              " 756: 'particular',\n",
              " 757: 'situado',\n",
              " 758: 'quienes',\n",
              " 759: 'descubrió',\n",
              " 760: 'paraná',\n",
              " 761: 'guayana',\n",
              " 762: 'contiene',\n",
              " 763: 'castellanos',\n",
              " 764: 'indígena',\n",
              " 765: '20',\n",
              " 766: 'variedad',\n",
              " 767: 'cuestión',\n",
              " 768: 'existe',\n",
              " 769: 'iberos',\n",
              " 770: 'hipótesis',\n",
              " 771: 'lado',\n",
              " 772: 'emitida',\n",
              " 773: 'habitada',\n",
              " 774: 'in',\n",
              " 775: 'afirma',\n",
              " 776: 'hércules',\n",
              " 777: 'hallaron',\n",
              " 778: 'riquezas',\n",
              " 779: 'cuba',\n",
              " 780: 'mexicanos',\n",
              " 781: 'edificios',\n",
              " 782: 'semejantes',\n",
              " 783: 'plumas',\n",
              " 784: 'ceremonias',\n",
              " 785: 'genebrardo',\n",
              " 786: 'salmanazar',\n",
              " 787: 'asiria',\n",
              " 788: 'parecer',\n",
              " 789: 'puerco',\n",
              " 790: 'real',\n",
              " 791: 'citada',\n",
              " 792: 'v',\n",
              " 793: 'política',\n",
              " 794: 'ciertos',\n",
              " 795: 'atlantes',\n",
              " 796: 'refiere',\n",
              " 797: 'inscripciones',\n",
              " 798: 'león',\n",
              " 799: 'cree',\n",
              " 800: 'destrucción',\n",
              " 801: 'siete',\n",
              " 802: 'eso',\n",
              " 803: 'tales',\n",
              " 804: 'principios',\n",
              " 805: 'probablemente',\n",
              " 806: 'documentos',\n",
              " 807: 'cierto',\n",
              " 808: 'puerto',\n",
              " 809: 'japón',\n",
              " 810: 'últimamente',\n",
              " 811: 'ninguna',\n",
              " 812: 'idioma',\n",
              " 813: 'compañeros',\n",
              " 814: 'tártaros',\n",
              " 815: 'figura',\n",
              " 816: 'desembarcaron',\n",
              " 817: 'ritos',\n",
              " 818: 'mas',\n",
              " 819: 'contacto',\n",
              " 820: 'vista',\n",
              " 821: 'pretende',\n",
              " 822: 'formas',\n",
              " 823: 'montano',\n",
              " 824: 'aurum',\n",
              " 825: 'polvo',\n",
              " 826: 'razón',\n",
              " 827: 'paru',\n",
              " 828: 'llegar',\n",
              " 829: 'dado',\n",
              " 830: 'etiopes',\n",
              " 831: 'dió',\n",
              " 832: 'atención',\n",
              " 833: 'annian',\n",
              " 834: 'última',\n",
              " 835: 'verdadero',\n",
              " 836: 'restos',\n",
              " 837: 'noche',\n",
              " 838: 'conclusiones',\n",
              " 839: 'hijos',\n",
              " 840: 'cam',\n",
              " 841: 'criador',\n",
              " 842: 'remonta',\n",
              " 843: 'anterior',\n",
              " 844: 'indudable',\n",
              " 845: 'hubieran',\n",
              " 846: 'filisteos',\n",
              " 847: 'capital',\n",
              " 848: 'roja',\n",
              " 849: 'rutas',\n",
              " 850: 'leguas',\n",
              " 851: 'autóctona',\n",
              " 852: 'encuentran',\n",
              " 853: 'palo',\n",
              " 854: 'propias',\n",
              " 855: 'dentro',\n",
              " 856: 'fierro',\n",
              " 857: 'cobre',\n",
              " 858: 'líquido',\n",
              " 859: 'aromática',\n",
              " 860: 'suave',\n",
              " 861: 'fina',\n",
              " 862: 'heridas',\n",
              " 863: 'pulpa',\n",
              " 864: 'veneno',\n",
              " 865: 'curan',\n",
              " 866: 'clases',\n",
              " 867: 'cera',\n",
              " 868: 'insecto',\n",
              " 869: 'hermosa',\n",
              " 870: 'mamífero',\n",
              " 871: 'perro',\n",
              " 872: 'gato',\n",
              " 873: 'tigre',\n",
              " 874: 'fines',\n",
              " 875: 'ramas',\n",
              " 876: 'rama',\n",
              " 877: 'población',\n",
              " 878: 'actual',\n",
              " 879: 'tenían',\n",
              " 880: 'embocadura',\n",
              " 881: 'septentrionales',\n",
              " 882: 'lagos',\n",
              " 883: 'unión',\n",
              " 884: 'aztecas',\n",
              " 885: 'anahuac',\n",
              " 886: 'colorado',\n",
              " 887: 'palenque',\n",
              " 888: 'parajes',\n",
              " 889: 'situadas',\n",
              " 890: 'pieles',\n",
              " 891: 'junto',\n",
              " 892: 'afluentes',\n",
              " 893: 'selvas',\n",
              " 894: 'magallanes',\n",
              " 895: 'tercera',\n",
              " 896: 'compuesta',\n",
              " 897: 'pampas',\n",
              " 898: 'salvajes',\n",
              " 899: 'igual',\n",
              " 900: 'principio',\n",
              " 901: 'desconocidas',\n",
              " 902: 'hallaba',\n",
              " 903: 'diversidad',\n",
              " 904: 'cultura',\n",
              " 905: 'llegado',\n",
              " 906: 'asiáticos',\n",
              " 907: 'últimas',\n",
              " 908: 'babel',\n",
              " 909: 'nieto',\n",
              " 910: 'imperios',\n",
              " 911: 'contemporáneos',\n",
              " 912: 'nuevamente',\n",
              " 913: 'postdiluviana',\n",
              " 914: 'navegaron',\n",
              " 915: 'columnas',\n",
              " 916: 'noticia',\n",
              " 917: 'belleza',\n",
              " 918: 'patria',\n",
              " 919: 'dirigirse',\n",
              " 920: 'española',\n",
              " 921: 'arquitectura',\n",
              " 922: 'arabia',\n",
              " 923: 'perdieron',\n",
              " 924: 'barlovento',\n",
              " 925: 'hespérides',\n",
              " 926: 'vers',\n",
              " 927: 'vocablos',\n",
              " 928: 'aceite',\n",
              " 929: 'creen',\n",
              " 930: 'inscripción',\n",
              " 931: 'parecen',\n",
              " 932: 'sean',\n",
              " 933: 'creencias',\n",
              " 934: 'humanos',\n",
              " 935: 'serpientes',\n",
              " 936: 'cierta',\n",
              " 937: 'conjeturas',\n",
              " 938: 'escrito',\n",
              " 939: 'vió',\n",
              " 940: 'meses',\n",
              " 941: 'veinte',\n",
              " 942: 'derrotados',\n",
              " 943: 'cien',\n",
              " 944: 'chino',\n",
              " 945: 'ojos',\n",
              " 946: 'establecieron',\n",
              " 947: 'descubierto',\n",
              " 948: 'bajeles',\n",
              " 949: 'cuzco',\n",
              " 950: 'conquistas',\n",
              " 951: 'completa',\n",
              " 952: 'vi',\n",
              " 953: 'treinta',\n",
              " 954: 'templo',\n",
              " 955: 'nace',\n",
              " 956: 'marfil',\n",
              " 957: 'mayores',\n",
              " 958: 'persia',\n",
              " 959: 'tartaria',\n",
              " 960: 'problema',\n",
              " 961: 'tanta',\n",
              " 962: 'nuestra',\n",
              " 963: 'timeo',\n",
              " 964: 'virtud',\n",
              " 965: 'cuna',\n",
              " 966: 'ptolomeo',\n",
              " 967: 'judea',\n",
              " 968: 'espartanos',\n",
              " 969: 'macedonia',\n",
              " 970: 'ciudades',\n",
              " 971: 'babilonia',\n",
              " 972: 'sublevación',\n",
              " 973: 'pocos',\n",
              " 974: 'valor',\n",
              " 975: 'huesos',\n",
              " 976: 'encontrados',\n",
              " 977: 'base',\n",
              " 978: 'corrientes',\n",
              " 979: 'navegantes',\n",
              " 980: 'xiv',\n",
              " 981: 'frutos',\n",
              " 982: 'mano',\n",
              " 983: 'terrestre',\n",
              " 984: 'pareja',\n",
              " 985: 'tronco',\n",
              " 986: 'producto',\n",
              " 987: 'especiales',\n",
              " 988: 'minerales',\n",
              " 989: 'pesos',\n",
              " 990: 'enteros',\n",
              " 991: 'fabricación',\n",
              " 992: 'sumamente',\n",
              " 993: 'finas',\n",
              " 994: 'matices',\n",
              " 995: 'semilla',\n",
              " 996: 'rosa',\n",
              " 997: 'medicinales',\n",
              " 998: 'parecida',\n",
              " 999: 'yerba',\n",
              " 1000: 'arábiga',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "gJgVhq1zwEpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc60593-8212-458d-c996-04c08b402f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9374"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Cantidad de palabras en el vocabulario\n",
        "vocab_size = len(tok.word_counts)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "gIg2e2WCwXbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6678ff7a-83e7-4452-cc62-a6692cdf3769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51724, 9374)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "y_data_int_offset = y_data_int - 1\n",
        "y_data = to_categorical(y_data_int_offset, num_classes=vocab_size) \n",
        "y_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "0cOmNZT_weK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a225155b-fbcb-452f-8730-d3f45ca8e806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# largo de la secuencia de entrada\n",
        "input_seq_len = x_data.shape[1] \n",
        "input_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "qtwITjgnwlgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7580880-27dc-4b8c-b05a-7baa82da8899"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9374"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Largo del vector de salida --> vocab_size\n",
        "output_size = vocab_size\n",
        "output_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "jzTZRXrrwrvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a129d46-f982-432f-ad77-3ff8e5a397b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 5)              46875     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 64)             17920     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 64)             0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9374)              309342    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 409,241\n",
            "Trainable params: 409,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 9374 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_length=input_seq_len))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64)) # La última capa LSTM no lleva return_sequences\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 9374 palabras posibles\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0322925a-fa80-4b95-b73e-cba722d53b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 3.1786 - accuracy: 0.3053 - val_loss: 18.7112 - val_accuracy: 0.0767\n",
            "Epoch 2/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 3.1642 - accuracy: 0.3089 - val_loss: 18.6836 - val_accuracy: 0.0787\n",
            "Epoch 3/100\n",
            "1294/1294 [==============================] - 12s 10ms/step - loss: 3.1445 - accuracy: 0.3106 - val_loss: 18.9899 - val_accuracy: 0.0780\n",
            "Epoch 4/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 3.1317 - accuracy: 0.3133 - val_loss: 18.9436 - val_accuracy: 0.0801\n",
            "Epoch 5/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 3.1058 - accuracy: 0.3167 - val_loss: 19.1860 - val_accuracy: 0.0812\n",
            "Epoch 6/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 3.0945 - accuracy: 0.3197 - val_loss: 19.6004 - val_accuracy: 0.0800\n",
            "Epoch 7/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 3.0792 - accuracy: 0.3200 - val_loss: 19.3920 - val_accuracy: 0.0772\n",
            "Epoch 8/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 3.0702 - accuracy: 0.3214 - val_loss: 19.4286 - val_accuracy: 0.0782\n",
            "Epoch 9/100\n",
            "1294/1294 [==============================] - 14s 11ms/step - loss: 3.0520 - accuracy: 0.3257 - val_loss: 19.5347 - val_accuracy: 0.0795\n",
            "Epoch 10/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 3.0317 - accuracy: 0.3269 - val_loss: 19.8035 - val_accuracy: 0.0797\n",
            "Epoch 11/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 3.0264 - accuracy: 0.3293 - val_loss: 19.8506 - val_accuracy: 0.0806\n",
            "Epoch 12/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 3.0117 - accuracy: 0.3314 - val_loss: 20.0198 - val_accuracy: 0.0743\n",
            "Epoch 13/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.9994 - accuracy: 0.3326 - val_loss: 19.9833 - val_accuracy: 0.0802\n",
            "Epoch 14/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.9930 - accuracy: 0.3336 - val_loss: 20.1698 - val_accuracy: 0.0795\n",
            "Epoch 15/100\n",
            "1294/1294 [==============================] - 15s 11ms/step - loss: 2.9726 - accuracy: 0.3359 - val_loss: 20.1192 - val_accuracy: 0.0778\n",
            "Epoch 16/100\n",
            "1294/1294 [==============================] - 14s 10ms/step - loss: 2.9563 - accuracy: 0.3389 - val_loss: 20.3192 - val_accuracy: 0.0792\n",
            "Epoch 17/100\n",
            "1294/1294 [==============================] - 15s 11ms/step - loss: 2.9382 - accuracy: 0.3424 - val_loss: 20.3943 - val_accuracy: 0.0760\n",
            "Epoch 18/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.9427 - accuracy: 0.3427 - val_loss: 20.5214 - val_accuracy: 0.0785\n",
            "Epoch 19/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.9225 - accuracy: 0.3452 - val_loss: 20.4591 - val_accuracy: 0.0791\n",
            "Epoch 20/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.9144 - accuracy: 0.3484 - val_loss: 20.5257 - val_accuracy: 0.0800\n",
            "Epoch 21/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.9014 - accuracy: 0.3497 - val_loss: 20.6529 - val_accuracy: 0.0768\n",
            "Epoch 22/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.8971 - accuracy: 0.3494 - val_loss: 20.6099 - val_accuracy: 0.0760\n",
            "Epoch 23/100\n",
            "1294/1294 [==============================] - 12s 10ms/step - loss: 2.8835 - accuracy: 0.3497 - val_loss: 20.9619 - val_accuracy: 0.0759\n",
            "Epoch 24/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.8713 - accuracy: 0.3537 - val_loss: 20.8852 - val_accuracy: 0.0760\n",
            "Epoch 25/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 2.8509 - accuracy: 0.3569 - val_loss: 21.1456 - val_accuracy: 0.0772\n",
            "Epoch 26/100\n",
            "1294/1294 [==============================] - 12s 10ms/step - loss: 2.8474 - accuracy: 0.3599 - val_loss: 21.0296 - val_accuracy: 0.0768\n",
            "Epoch 27/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.8365 - accuracy: 0.3606 - val_loss: 21.2208 - val_accuracy: 0.0756\n",
            "Epoch 28/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.8267 - accuracy: 0.3624 - val_loss: 21.2237 - val_accuracy: 0.0778\n",
            "Epoch 29/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.8240 - accuracy: 0.3613 - val_loss: 21.2829 - val_accuracy: 0.0782\n",
            "Epoch 30/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.8134 - accuracy: 0.3626 - val_loss: 21.4850 - val_accuracy: 0.0788\n",
            "Epoch 31/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.8040 - accuracy: 0.3637 - val_loss: 21.4360 - val_accuracy: 0.0789\n",
            "Epoch 32/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.7956 - accuracy: 0.3671 - val_loss: 21.2991 - val_accuracy: 0.0747\n",
            "Epoch 33/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.7821 - accuracy: 0.3694 - val_loss: 21.7229 - val_accuracy: 0.0758\n",
            "Epoch 34/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.7807 - accuracy: 0.3677 - val_loss: 21.5283 - val_accuracy: 0.0786\n",
            "Epoch 35/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.7665 - accuracy: 0.3719 - val_loss: 21.5822 - val_accuracy: 0.0791\n",
            "Epoch 36/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.7627 - accuracy: 0.3697 - val_loss: 21.7044 - val_accuracy: 0.0735\n",
            "Epoch 37/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.7492 - accuracy: 0.3761 - val_loss: 21.9522 - val_accuracy: 0.0768\n",
            "Epoch 38/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.7428 - accuracy: 0.3763 - val_loss: 21.9303 - val_accuracy: 0.0758\n",
            "Epoch 39/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.7208 - accuracy: 0.3812 - val_loss: 22.0804 - val_accuracy: 0.0777\n",
            "Epoch 40/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.7165 - accuracy: 0.3779 - val_loss: 22.1445 - val_accuracy: 0.0775\n",
            "Epoch 41/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.7224 - accuracy: 0.3797 - val_loss: 22.2012 - val_accuracy: 0.0768\n",
            "Epoch 42/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.7104 - accuracy: 0.3798 - val_loss: 22.2003 - val_accuracy: 0.0797\n",
            "Epoch 43/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.6980 - accuracy: 0.3845 - val_loss: 22.1537 - val_accuracy: 0.0784\n",
            "Epoch 44/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.6977 - accuracy: 0.3796 - val_loss: 22.3939 - val_accuracy: 0.0766\n",
            "Epoch 45/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6915 - accuracy: 0.3852 - val_loss: 22.5184 - val_accuracy: 0.0768\n",
            "Epoch 46/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.6830 - accuracy: 0.3831 - val_loss: 22.5155 - val_accuracy: 0.0776\n",
            "Epoch 47/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6777 - accuracy: 0.3866 - val_loss: 22.4313 - val_accuracy: 0.0768\n",
            "Epoch 48/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.6726 - accuracy: 0.3878 - val_loss: 22.4905 - val_accuracy: 0.0782\n",
            "Epoch 49/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.6621 - accuracy: 0.3894 - val_loss: 22.6659 - val_accuracy: 0.0768\n",
            "Epoch 50/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.6531 - accuracy: 0.3901 - val_loss: 22.7000 - val_accuracy: 0.0774\n",
            "Epoch 51/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6498 - accuracy: 0.3910 - val_loss: 22.9329 - val_accuracy: 0.0769\n",
            "Epoch 52/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6382 - accuracy: 0.3929 - val_loss: 22.8551 - val_accuracy: 0.0787\n",
            "Epoch 53/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6408 - accuracy: 0.3934 - val_loss: 22.9118 - val_accuracy: 0.0745\n",
            "Epoch 54/100\n",
            "1294/1294 [==============================] - 12s 10ms/step - loss: 2.6277 - accuracy: 0.3981 - val_loss: 22.9174 - val_accuracy: 0.0775\n",
            "Epoch 55/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.6234 - accuracy: 0.3970 - val_loss: 22.6448 - val_accuracy: 0.0742\n",
            "Epoch 56/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.6152 - accuracy: 0.3996 - val_loss: 23.1535 - val_accuracy: 0.0775\n",
            "Epoch 57/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.6080 - accuracy: 0.3969 - val_loss: 22.8953 - val_accuracy: 0.0739\n",
            "Epoch 58/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5990 - accuracy: 0.3994 - val_loss: 23.0118 - val_accuracy: 0.0781\n",
            "Epoch 59/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5942 - accuracy: 0.4000 - val_loss: 23.3989 - val_accuracy: 0.0748\n",
            "Epoch 60/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.5888 - accuracy: 0.4014 - val_loss: 22.9218 - val_accuracy: 0.0778\n",
            "Epoch 61/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5843 - accuracy: 0.4027 - val_loss: 23.1558 - val_accuracy: 0.0753\n",
            "Epoch 62/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.5746 - accuracy: 0.4024 - val_loss: 22.9078 - val_accuracy: 0.0755\n",
            "Epoch 63/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5732 - accuracy: 0.4051 - val_loss: 23.1000 - val_accuracy: 0.0766\n",
            "Epoch 64/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5708 - accuracy: 0.4046 - val_loss: 23.5961 - val_accuracy: 0.0756\n",
            "Epoch 65/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5616 - accuracy: 0.4067 - val_loss: 23.3744 - val_accuracy: 0.0774\n",
            "Epoch 66/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5551 - accuracy: 0.4064 - val_loss: 23.1817 - val_accuracy: 0.0722\n",
            "Epoch 67/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5582 - accuracy: 0.4050 - val_loss: 23.5120 - val_accuracy: 0.0725\n",
            "Epoch 68/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5441 - accuracy: 0.4097 - val_loss: 23.6859 - val_accuracy: 0.0797\n",
            "Epoch 69/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5415 - accuracy: 0.4085 - val_loss: 23.4701 - val_accuracy: 0.0775\n",
            "Epoch 70/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5408 - accuracy: 0.4105 - val_loss: 23.5060 - val_accuracy: 0.0748\n",
            "Epoch 71/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5311 - accuracy: 0.4115 - val_loss: 23.7057 - val_accuracy: 0.0737\n",
            "Epoch 72/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5339 - accuracy: 0.4132 - val_loss: 23.9069 - val_accuracy: 0.0772\n",
            "Epoch 73/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.5301 - accuracy: 0.4135 - val_loss: 23.8587 - val_accuracy: 0.0787\n",
            "Epoch 74/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5105 - accuracy: 0.4181 - val_loss: 23.7029 - val_accuracy: 0.0752\n",
            "Epoch 75/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5133 - accuracy: 0.4143 - val_loss: 23.5778 - val_accuracy: 0.0753\n",
            "Epoch 76/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5054 - accuracy: 0.4167 - val_loss: 23.8565 - val_accuracy: 0.0754\n",
            "Epoch 77/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.5074 - accuracy: 0.4146 - val_loss: 23.8313 - val_accuracy: 0.0739\n",
            "Epoch 78/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.4997 - accuracy: 0.4182 - val_loss: 23.9417 - val_accuracy: 0.0756\n",
            "Epoch 79/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.5001 - accuracy: 0.4175 - val_loss: 23.9165 - val_accuracy: 0.0744\n",
            "Epoch 80/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4870 - accuracy: 0.4215 - val_loss: 23.9766 - val_accuracy: 0.0737\n",
            "Epoch 81/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4855 - accuracy: 0.4204 - val_loss: 23.8376 - val_accuracy: 0.0736\n",
            "Epoch 82/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4863 - accuracy: 0.4194 - val_loss: 24.0546 - val_accuracy: 0.0762\n",
            "Epoch 83/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4724 - accuracy: 0.4228 - val_loss: 24.1803 - val_accuracy: 0.0780\n",
            "Epoch 84/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4782 - accuracy: 0.4239 - val_loss: 24.1460 - val_accuracy: 0.0723\n",
            "Epoch 85/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4651 - accuracy: 0.4236 - val_loss: 24.1708 - val_accuracy: 0.0744\n",
            "Epoch 86/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4601 - accuracy: 0.4268 - val_loss: 24.2140 - val_accuracy: 0.0770\n",
            "Epoch 87/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4577 - accuracy: 0.4274 - val_loss: 24.1529 - val_accuracy: 0.0738\n",
            "Epoch 88/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4623 - accuracy: 0.4255 - val_loss: 24.2615 - val_accuracy: 0.0733\n",
            "Epoch 89/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4513 - accuracy: 0.4290 - val_loss: 24.2497 - val_accuracy: 0.0728\n",
            "Epoch 90/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4455 - accuracy: 0.4265 - val_loss: 24.4554 - val_accuracy: 0.0764\n",
            "Epoch 91/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.4400 - accuracy: 0.4307 - val_loss: 24.2815 - val_accuracy: 0.0744\n",
            "Epoch 92/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4447 - accuracy: 0.4266 - val_loss: 24.3726 - val_accuracy: 0.0720\n",
            "Epoch 93/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4292 - accuracy: 0.4303 - val_loss: 24.5648 - val_accuracy: 0.0749\n",
            "Epoch 94/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4242 - accuracy: 0.4324 - val_loss: 24.4575 - val_accuracy: 0.0720\n",
            "Epoch 95/100\n",
            "1294/1294 [==============================] - 13s 10ms/step - loss: 2.4308 - accuracy: 0.4315 - val_loss: 24.4231 - val_accuracy: 0.0759\n",
            "Epoch 96/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4256 - accuracy: 0.4333 - val_loss: 24.5507 - val_accuracy: 0.0742\n",
            "Epoch 97/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4148 - accuracy: 0.4335 - val_loss: 24.5889 - val_accuracy: 0.0756\n",
            "Epoch 98/100\n",
            "1294/1294 [==============================] - 11s 9ms/step - loss: 2.4150 - accuracy: 0.4355 - val_loss: 24.7124 - val_accuracy: 0.0749\n",
            "Epoch 99/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4148 - accuracy: 0.4342 - val_loss: 24.6169 - val_accuracy: 0.0739\n",
            "Epoch 100/100\n",
            "1294/1294 [==============================] - 12s 9ms/step - loss: 2.4117 - accuracy: 0.4346 - val_loss: 24.8762 - val_accuracy: 0.0750\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(x_data, y_data, epochs=100, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "q_orBXOrCsNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "6a5d5f19-c9a8-4584-94b7-e8dfb37e35d4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos un segundo modelo similar al anterior, pero con más capas intermedias. También subimos el dropout a 0.5 (el valor por defecto) "
      ],
      "metadata": {
        "id": "WLQhaKNcuCoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 9374 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model2.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_length=input_seq_len))\n",
        "\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(64)) # La última capa LSTM no lleva return_sequences\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 9374 palabras posibles\n",
        "model2.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjByDIPLgG5A",
        "outputId": "298659f6-deb2-4997-9f99-9e56114702ca"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 3, 5)              46875     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 3, 64)             17920     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3, 64)             0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 3, 64)             33024     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 64)             0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 3, 64)             33024     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 3, 64)             0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 9374)              309342    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 475,289\n",
            "Trainable params: 475,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist2 = model2.fit(x_data, y_data, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQKKOH_gcug",
        "outputId": "56254e64-67be-41b9-975c-e74629da402b"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1294/1294 [==============================] - 27s 17ms/step - loss: 7.1311 - accuracy: 0.0781 - val_loss: 7.3052 - val_accuracy: 0.0814\n",
            "Epoch 2/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 6.7291 - accuracy: 0.0782 - val_loss: 7.5216 - val_accuracy: 0.0814\n",
            "Epoch 3/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 6.6677 - accuracy: 0.0782 - val_loss: 7.6374 - val_accuracy: 0.0814\n",
            "Epoch 4/100\n",
            "1294/1294 [==============================] - 20s 15ms/step - loss: 6.6346 - accuracy: 0.0782 - val_loss: 7.8462 - val_accuracy: 0.0814\n",
            "Epoch 5/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 6.5771 - accuracy: 0.0783 - val_loss: 7.9802 - val_accuracy: 0.0800\n",
            "Epoch 6/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 6.5131 - accuracy: 0.0783 - val_loss: 8.0905 - val_accuracy: 0.0797\n",
            "Epoch 7/100\n",
            "1294/1294 [==============================] - 21s 16ms/step - loss: 6.4317 - accuracy: 0.0784 - val_loss: 8.2169 - val_accuracy: 0.0799\n",
            "Epoch 8/100\n",
            "1294/1294 [==============================] - 19s 15ms/step - loss: 6.3331 - accuracy: 0.0792 - val_loss: 8.3615 - val_accuracy: 0.0781\n",
            "Epoch 9/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 6.2230 - accuracy: 0.0830 - val_loss: 8.4106 - val_accuracy: 0.0753\n",
            "Epoch 10/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 6.0938 - accuracy: 0.0846 - val_loss: 8.3940 - val_accuracy: 0.0733\n",
            "Epoch 11/100\n",
            "1294/1294 [==============================] - 19s 14ms/step - loss: 5.9716 - accuracy: 0.0876 - val_loss: 8.5221 - val_accuracy: 0.0737\n",
            "Epoch 12/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 5.8755 - accuracy: 0.0897 - val_loss: 8.6668 - val_accuracy: 0.0740\n",
            "Epoch 13/100\n",
            "1294/1294 [==============================] - 19s 15ms/step - loss: 5.7880 - accuracy: 0.0927 - val_loss: 8.7414 - val_accuracy: 0.0763\n",
            "Epoch 14/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 5.7077 - accuracy: 0.0928 - val_loss: 8.8600 - val_accuracy: 0.0736\n",
            "Epoch 15/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 5.6288 - accuracy: 0.0957 - val_loss: 9.0202 - val_accuracy: 0.0732\n",
            "Epoch 16/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 5.5546 - accuracy: 0.0981 - val_loss: 9.2471 - val_accuracy: 0.0778\n",
            "Epoch 17/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 5.4868 - accuracy: 0.0998 - val_loss: 9.3733 - val_accuracy: 0.0755\n",
            "Epoch 18/100\n",
            "1294/1294 [==============================] - 21s 17ms/step - loss: 5.4146 - accuracy: 0.1025 - val_loss: 9.4297 - val_accuracy: 0.0776\n",
            "Epoch 19/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 5.3461 - accuracy: 0.1059 - val_loss: 9.6688 - val_accuracy: 0.0753\n",
            "Epoch 20/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.2837 - accuracy: 0.1067 - val_loss: 9.7655 - val_accuracy: 0.0764\n",
            "Epoch 21/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.2193 - accuracy: 0.1095 - val_loss: 10.0160 - val_accuracy: 0.0763\n",
            "Epoch 22/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.1656 - accuracy: 0.1122 - val_loss: 10.2550 - val_accuracy: 0.0756\n",
            "Epoch 23/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.1140 - accuracy: 0.1136 - val_loss: 10.3946 - val_accuracy: 0.0760\n",
            "Epoch 24/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.0673 - accuracy: 0.1165 - val_loss: 10.5004 - val_accuracy: 0.0763\n",
            "Epoch 25/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 5.0240 - accuracy: 0.1182 - val_loss: 10.7137 - val_accuracy: 0.0769\n",
            "Epoch 26/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.9690 - accuracy: 0.1195 - val_loss: 10.9432 - val_accuracy: 0.0749\n",
            "Epoch 27/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.9290 - accuracy: 0.1223 - val_loss: 10.9956 - val_accuracy: 0.0740\n",
            "Epoch 28/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.8843 - accuracy: 0.1238 - val_loss: 11.3253 - val_accuracy: 0.0725\n",
            "Epoch 29/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.8432 - accuracy: 0.1262 - val_loss: 11.4909 - val_accuracy: 0.0738\n",
            "Epoch 30/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.8063 - accuracy: 0.1274 - val_loss: 11.6861 - val_accuracy: 0.0752\n",
            "Epoch 31/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.7714 - accuracy: 0.1288 - val_loss: 11.8299 - val_accuracy: 0.0724\n",
            "Epoch 32/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.7390 - accuracy: 0.1320 - val_loss: 11.8401 - val_accuracy: 0.0765\n",
            "Epoch 33/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.7036 - accuracy: 0.1339 - val_loss: 12.1087 - val_accuracy: 0.0739\n",
            "Epoch 34/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 4.6760 - accuracy: 0.1340 - val_loss: 12.1216 - val_accuracy: 0.0739\n",
            "Epoch 35/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.6428 - accuracy: 0.1373 - val_loss: 12.4078 - val_accuracy: 0.0725\n",
            "Epoch 36/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.6102 - accuracy: 0.1381 - val_loss: 12.4950 - val_accuracy: 0.0735\n",
            "Epoch 37/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 4.5941 - accuracy: 0.1393 - val_loss: 12.7576 - val_accuracy: 0.0734\n",
            "Epoch 38/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.5608 - accuracy: 0.1409 - val_loss: 12.8180 - val_accuracy: 0.0751\n",
            "Epoch 39/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.5289 - accuracy: 0.1425 - val_loss: 12.9699 - val_accuracy: 0.0731\n",
            "Epoch 40/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.5090 - accuracy: 0.1437 - val_loss: 13.0548 - val_accuracy: 0.0724\n",
            "Epoch 41/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.4875 - accuracy: 0.1451 - val_loss: 13.2451 - val_accuracy: 0.0736\n",
            "Epoch 42/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.4687 - accuracy: 0.1461 - val_loss: 13.3763 - val_accuracy: 0.0730\n",
            "Epoch 43/100\n",
            "1294/1294 [==============================] - 19s 15ms/step - loss: 4.4428 - accuracy: 0.1474 - val_loss: 13.4462 - val_accuracy: 0.0723\n",
            "Epoch 44/100\n",
            "1294/1294 [==============================] - 21s 16ms/step - loss: 4.4140 - accuracy: 0.1486 - val_loss: 13.4623 - val_accuracy: 0.0717\n",
            "Epoch 45/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.4076 - accuracy: 0.1505 - val_loss: 13.7721 - val_accuracy: 0.0715\n",
            "Epoch 46/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.3835 - accuracy: 0.1504 - val_loss: 13.6590 - val_accuracy: 0.0727\n",
            "Epoch 47/100\n",
            "1294/1294 [==============================] - 19s 14ms/step - loss: 4.3531 - accuracy: 0.1529 - val_loss: 14.0557 - val_accuracy: 0.0741\n",
            "Epoch 48/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.3416 - accuracy: 0.1541 - val_loss: 14.0483 - val_accuracy: 0.0714\n",
            "Epoch 49/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.3315 - accuracy: 0.1542 - val_loss: 14.0405 - val_accuracy: 0.0716\n",
            "Epoch 50/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.3075 - accuracy: 0.1562 - val_loss: 14.1485 - val_accuracy: 0.0687\n",
            "Epoch 51/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.2897 - accuracy: 0.1570 - val_loss: 14.3575 - val_accuracy: 0.0710\n",
            "Epoch 52/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.2747 - accuracy: 0.1600 - val_loss: 14.3763 - val_accuracy: 0.0706\n",
            "Epoch 53/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.2608 - accuracy: 0.1596 - val_loss: 14.5467 - val_accuracy: 0.0709\n",
            "Epoch 54/100\n",
            "1294/1294 [==============================] - 19s 15ms/step - loss: 4.2475 - accuracy: 0.1610 - val_loss: 14.6024 - val_accuracy: 0.0718\n",
            "Epoch 55/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.2306 - accuracy: 0.1630 - val_loss: 14.8879 - val_accuracy: 0.0711\n",
            "Epoch 56/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.2171 - accuracy: 0.1625 - val_loss: 14.7243 - val_accuracy: 0.0713\n",
            "Epoch 57/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.2009 - accuracy: 0.1647 - val_loss: 14.7919 - val_accuracy: 0.0725\n",
            "Epoch 58/100\n",
            "1294/1294 [==============================] - 19s 15ms/step - loss: 4.1898 - accuracy: 0.1660 - val_loss: 15.1149 - val_accuracy: 0.0699\n",
            "Epoch 59/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.1752 - accuracy: 0.1645 - val_loss: 14.9652 - val_accuracy: 0.0700\n",
            "Epoch 60/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.1554 - accuracy: 0.1664 - val_loss: 15.1579 - val_accuracy: 0.0705\n",
            "Epoch 61/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.1491 - accuracy: 0.1673 - val_loss: 15.3472 - val_accuracy: 0.0688\n",
            "Epoch 62/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.1460 - accuracy: 0.1663 - val_loss: 15.1831 - val_accuracy: 0.0707\n",
            "Epoch 63/100\n",
            "1294/1294 [==============================] - 19s 14ms/step - loss: 4.1205 - accuracy: 0.1714 - val_loss: 15.3984 - val_accuracy: 0.0712\n",
            "Epoch 64/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.1045 - accuracy: 0.1700 - val_loss: 15.4722 - val_accuracy: 0.0712\n",
            "Epoch 65/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 4.0964 - accuracy: 0.1710 - val_loss: 15.4828 - val_accuracy: 0.0685\n",
            "Epoch 66/100\n",
            "1294/1294 [==============================] - 20s 15ms/step - loss: 4.0825 - accuracy: 0.1735 - val_loss: 15.5563 - val_accuracy: 0.0696\n",
            "Epoch 67/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.0847 - accuracy: 0.1741 - val_loss: 15.5462 - val_accuracy: 0.0724\n",
            "Epoch 68/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 4.0525 - accuracy: 0.1753 - val_loss: 15.6808 - val_accuracy: 0.0715\n",
            "Epoch 69/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.0541 - accuracy: 0.1766 - val_loss: 15.7623 - val_accuracy: 0.0712\n",
            "Epoch 70/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.0400 - accuracy: 0.1743 - val_loss: 15.8603 - val_accuracy: 0.0728\n",
            "Epoch 71/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.0345 - accuracy: 0.1776 - val_loss: 15.8888 - val_accuracy: 0.0728\n",
            "Epoch 72/100\n",
            "1294/1294 [==============================] - 18s 14ms/step - loss: 4.0188 - accuracy: 0.1771 - val_loss: 15.7999 - val_accuracy: 0.0696\n",
            "Epoch 73/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.0050 - accuracy: 0.1804 - val_loss: 16.1119 - val_accuracy: 0.0728\n",
            "Epoch 74/100\n",
            "1294/1294 [==============================] - 16s 13ms/step - loss: 4.0016 - accuracy: 0.1792 - val_loss: 16.1422 - val_accuracy: 0.0711\n",
            "Epoch 75/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.9898 - accuracy: 0.1805 - val_loss: 16.1578 - val_accuracy: 0.0701\n",
            "Epoch 76/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.9817 - accuracy: 0.1805 - val_loss: 16.4732 - val_accuracy: 0.0695\n",
            "Epoch 77/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.9786 - accuracy: 0.1813 - val_loss: 16.1910 - val_accuracy: 0.0688\n",
            "Epoch 78/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.9585 - accuracy: 0.1827 - val_loss: 16.3179 - val_accuracy: 0.0702\n",
            "Epoch 79/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.9522 - accuracy: 0.1838 - val_loss: 16.4608 - val_accuracy: 0.0688\n",
            "Epoch 80/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.9465 - accuracy: 0.1830 - val_loss: 16.4830 - val_accuracy: 0.0708\n",
            "Epoch 81/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.9352 - accuracy: 0.1846 - val_loss: 16.4513 - val_accuracy: 0.0707\n",
            "Epoch 82/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.9187 - accuracy: 0.1838 - val_loss: 16.6781 - val_accuracy: 0.0682\n",
            "Epoch 83/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.9141 - accuracy: 0.1862 - val_loss: 16.7124 - val_accuracy: 0.0700\n",
            "Epoch 84/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.9050 - accuracy: 0.1869 - val_loss: 16.6572 - val_accuracy: 0.0678\n",
            "Epoch 85/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8932 - accuracy: 0.1907 - val_loss: 16.8641 - val_accuracy: 0.0699\n",
            "Epoch 86/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8895 - accuracy: 0.1884 - val_loss: 16.8105 - val_accuracy: 0.0685\n",
            "Epoch 87/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.8740 - accuracy: 0.1894 - val_loss: 17.0171 - val_accuracy: 0.0710\n",
            "Epoch 88/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.8642 - accuracy: 0.1899 - val_loss: 17.0062 - val_accuracy: 0.0715\n",
            "Epoch 89/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.8724 - accuracy: 0.1893 - val_loss: 16.7228 - val_accuracy: 0.0681\n",
            "Epoch 90/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8566 - accuracy: 0.1921 - val_loss: 16.9554 - val_accuracy: 0.0656\n",
            "Epoch 91/100\n",
            "1294/1294 [==============================] - 20s 15ms/step - loss: 3.8507 - accuracy: 0.1931 - val_loss: 16.9435 - val_accuracy: 0.0698\n",
            "Epoch 92/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.8446 - accuracy: 0.1930 - val_loss: 17.1921 - val_accuracy: 0.0711\n",
            "Epoch 93/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8326 - accuracy: 0.1915 - val_loss: 17.3288 - val_accuracy: 0.0693\n",
            "Epoch 94/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8276 - accuracy: 0.1951 - val_loss: 17.2046 - val_accuracy: 0.0670\n",
            "Epoch 95/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.8102 - accuracy: 0.1981 - val_loss: 17.4259 - val_accuracy: 0.0667\n",
            "Epoch 96/100\n",
            "1294/1294 [==============================] - 16s 12ms/step - loss: 3.8081 - accuracy: 0.1967 - val_loss: 17.3397 - val_accuracy: 0.0692\n",
            "Epoch 97/100\n",
            "1294/1294 [==============================] - 15s 12ms/step - loss: 3.8029 - accuracy: 0.1981 - val_loss: 17.3843 - val_accuracy: 0.0716\n",
            "Epoch 98/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.7946 - accuracy: 0.2000 - val_loss: 17.3941 - val_accuracy: 0.0692\n",
            "Epoch 99/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.7944 - accuracy: 0.1990 - val_loss: 17.2991 - val_accuracy: 0.0670\n",
            "Epoch 100/100\n",
            "1294/1294 [==============================] - 17s 13ms/step - loss: 3.7809 - accuracy: 0.2005 - val_loss: 17.5325 - val_accuracy: 0.0703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento modelo 2\n",
        "epoch_count = range(1, len(hist2.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist2.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist2.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0hGiEkgTj-4S",
        "outputId": "1fd3dcdd-2327-4324-9332-fddfcac1af9a"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primeras conclusiones\n",
        "- Ninguno de los dos modelos mostró buenos resultados. En ambos casos hay overfitting.\n",
        "- En train, 100 epochs mostraron una mejor accuracy que los 50 con los que se había entrenado originalmente, pero aún así es la métrica es bastante baja.\n"
      ],
      "metadata": {
        "id": "r_NaYBTFugZz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "### 5 - Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy_AXWQWzeeE"
      },
      "outputs": [],
      "source": [
        "# Keras pad_sequences\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "\n",
        "# Ajustar la secuencia de entrada al tamaño fijo (3).\n",
        "# Si supera el tamaño, se trunca\n",
        "# Si es más corta, se agrega un prefijo con ceros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [],
      "source": [
        "# Recibe un texto y un modelo y retorna la predicción\n",
        "def model_response(human_text, m):\n",
        "\n",
        "    # encoding\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=3, padding='pre')\n",
        "    \n",
        "    # predicción softmax\n",
        "    y_hat = m.predict(encoded).argmax(axis=-1)\n",
        "\n",
        "    # palabra que corresponde al indice (y_hat) predicho por el modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # frase predicha + predicción\n",
        "    return human_text + ' ' + out_word\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# probamos la función de predicción con un texto de ejemplo \n",
        "model_response('Santo Domingo', model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tJrD5NAfwzLG",
        "outputId": "7be53ecd-2852-4a7c-b709-9ee52a8dd5c9"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Santo Domingo más'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_response('trataban a los indios como si fueran ', model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gM98K-dT2Xz3",
        "outputId": "84f2a3d4-a2f4-4e80-e1d4-18bec7a8d9e1"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trataban a los indios como si fueran  fundándose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos con algunos textos de ejemplo para ver las respuestas con ambos modelos."
      ],
      "metadata": {
        "id": "bgMhtFKWhtq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = ['los conquistadores del río', 'aztecas, mayas, griegos,', 'trataban a los indios como si fueran',\n",
        "         'Santo Domingo', 'fueron explorados como', 'no tuvieron', 'sus bosques tupidos', 'provincia de San Juan y',\n",
        "         'árbol cuya madera es','sus grandes hojas']\n",
        "for _,input_text in enumerate(input):\n",
        "  output = model_response(input_text, model)\n",
        "  output2 = model_response(input_text, model2)\n",
        "  print(f\"{input_text}\\n M1 >>>{output}\\n M2 >>>{output2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QKGaZbhTm6U",
        "outputId": "9066763e-6d3f-40b2-9f07-7637e02b686f"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "los conquistadores del río\n",
            " M1 >>>los conquistadores del río parálisis\n",
            " M2 >>>los conquistadores del río cabildo\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "aztecas, mayas, griegos,\n",
            " M1 >>>aztecas, mayas, griegos, piedra\n",
            " M2 >>>aztecas, mayas, griegos, ahora\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "trataban a los indios como si fueran\n",
            " M1 >>>trataban a los indios como si fueran fundándose\n",
            " M2 >>>trataban a los indios como si fueran árboles\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Santo Domingo\n",
            " M1 >>>Santo Domingo más\n",
            " M2 >>>Santo Domingo y\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "fueron explorados como\n",
            " M1 >>>fueron explorados como en\n",
            " M2 >>>fueron explorados como y\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "no tuvieron\n",
            " M1 >>>no tuvieron sacrificio\n",
            " M2 >>>no tuvieron batalla\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "sus bosques tupidos\n",
            " M1 >>>sus bosques tupidos prehistóricos\n",
            " M2 >>>sus bosques tupidos consistente\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "provincia de San Juan y\n",
            " M1 >>>provincia de San Juan y collingast\n",
            " M2 >>>provincia de San Juan y collingast\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "árbol cuya madera es\n",
            " M1 >>>árbol cuya madera es guapurú\n",
            " M2 >>>árbol cuya madera es duro\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "sus grandes hojas\n",
            " M1 >>>sus grandes hojas sud\n",
            " M2 >>>sus grandes hojas y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### 6 - Generación de secuencias nuevas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "# Modelo autoregresivo\n",
        "def generate_seq(m, tokenizer, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            m (keras): modelo entrenado\n",
        "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\n",
        "    for _ in range(n_words):\n",
        "\t\t    # encoding\n",
        "        encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t\n",
        "    \t\t# predicción softmax\n",
        "        y_hat = m.predict(encoded).argmax(axis=-1)\n",
        "\n",
        "        # palabra que corresponde al índice (y_hat) predicho por el modelo\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_hat:\n",
        "                out_word = word\n",
        "                break\n",
        "\n",
        "        # frase predicha + predicción\n",
        "\t\t    # (se usa como input en la próxima predicción \n",
        "        output_text += ' ' + out_word\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1343b583-1e2b-4af4-b8e5-ab7649804a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Santo Domingo más cuyos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        " # Probamos la función con el mismo texto que antes ... \n",
        "generate_seq(model, tok, 'Santo Domingo', max_length=3, n_words=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a probar ambos modelos con la misma secuencia de textos, pero esta vez para predecir dos palabras."
      ],
      "metadata": {
        "id": "oMrlO9_vxNzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _,input_text in enumerate(input):\n",
        "  output = generate_seq(model, tok, input_text, max_length=3, n_words=2)\n",
        "  output2 = generate_seq(model2, tok, input_text, max_length=3, n_words=2)\n",
        "  print(f\"{input_text}\\n M1 >>>{output}\\n M2 >>>{output2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KheJFZslg7A",
        "outputId": "1c9e7ae0-abb5-4ea2-f72c-735c476dd55e"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "los conquistadores del río\n",
            " M1 >>>los conquistadores del río parálisis por\n",
            " M2 >>>los conquistadores del río cabildo \n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "aztecas, mayas, griegos,\n",
            " M1 >>>aztecas, mayas, griegos, piedra no\n",
            " M2 >>>aztecas, mayas, griegos, ahora la\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "trataban a los indios como si fueran\n",
            " M1 >>>trataban a los indios como si fueran fundándose reiteradas\n",
            " M2 >>>trataban a los indios como si fueran árboles la\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Santo Domingo\n",
            " M1 >>>Santo Domingo más cuyos\n",
            " M2 >>>Santo Domingo y de\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "fueron explorados como\n",
            " M1 >>>fueron explorados como en y\n",
            " M2 >>>fueron explorados como y en\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "no tuvieron\n",
            " M1 >>>no tuvieron sacrificio misión\n",
            " M2 >>>no tuvieron batalla las\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "sus bosques tupidos\n",
            " M1 >>>sus bosques tupidos prehistóricos y\n",
            " M2 >>>sus bosques tupidos consistente \n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "provincia de San Juan y\n",
            " M1 >>>provincia de San Juan y collingast las\n",
            " M2 >>>provincia de San Juan y collingast la\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "árbol cuya madera es\n",
            " M1 >>>árbol cuya madera es guapurú por\n",
            " M2 >>>árbol cuya madera es duro y\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "sus grandes hojas\n",
            " M1 >>>sus grandes hojas sud y\n",
            " M2 >>>sus grandes hojas y aplicadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2SHmXbgxQH9"
      },
      "source": [
        "## Conclusiones\n",
        "En base al accuracy, habíamos observado que los resultados de entrenar estos dos modelos no había sido bueno.\n",
        "Al mirar las predicciones con algunos textos de ejemplo tampoco se ven resultados de interés; algunas predicciones fueron originales (*trataban a los indios como si fueran árboles*), otras sin sentido (*provincia de San Juan y collingast*). En conclusión, no puede decirse que alguno de los dos modelos propuestos sea mejor (o peor) que el otro.\n",
        "\n",
        "Las pruebas que se realizaron consistieron en empezar con un modelo base y experimentar con más epochs y con más capas. Se podría considerar probar con más neuronas, agregar BRNN, trabajar con un corpus mayor (se intentó pero el Google Colab se quedó sin recursos), probar otro largo de secuencia, o usar embeddings pre-entrenados."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "T2SHmXbgxQH9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}